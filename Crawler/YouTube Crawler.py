from googleapiclient.discovery import build
import pandas as pd
import time

# ----------------------------------------------------
# ì„¤ì •
# ----------------------------------------------------
# ğŸ”‘ ë°œê¸‰ë°›ì€ API í‚¤ (ë³´ì•ˆì„ ìœ„í•´ ì‹¤ì œ í‚¤ë¡œ ëŒ€ì²´í•´ì£¼ì„¸ìš”)
API_KEY = "AIzaSyA4VJl2K-81ERhBZRQjJe5x0E40gGgTzPs"
SEARCH_QUERY = "ì‚¬ìš©ë²•"  # ê²€ìƒ‰í•  í‚¤ì›Œë“œ
MAX_VIDEOS = 10  # ê°€ì ¸ì˜¬ ì˜ìƒ ê°œìˆ˜ (ìµœëŒ€ 50ê°œ * í˜ì´ì§€ ìˆ˜)

# ----------------------------------------------------
# API ë¹Œë“œ
# ----------------------------------------------------
try:
    youtube = build("youtube", "v3", developerKey=API_KEY)
except Exception as e:
    print(f"âŒ API í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
    print("API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    exit()


def search_videos(query, max_results):
    """
    í‚¤ì›Œë“œë¡œ ìœ íŠœë¸Œ ì˜ìƒ ê²€ìƒ‰.
    ì˜ìƒ ID, ì œëª©, ì„¤ëª…ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    print(f"ğŸ” '{query}' í‚¤ì›Œë“œë¡œ ì˜ìƒ ê²€ìƒ‰ ì‹œì‘...")
    videos = []
    try:
        request = youtube.search().list(
            part="snippet",
            q=query,
            type="video",
            maxResults=max_results
        )
        response = request.execute()

        for item in response["items"]:
            video_id = item["id"]["videoId"]
            title = item["snippet"]["title"]
            # 'content' ì»¬ëŸ¼ì„ ìœ„í•´ ì˜ìƒ ì„¤ëª…ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
            description = item["snippet"]["description"]
            videos.append((video_id, title, description))

        print(f"âœ… ì´ {len(videos)}ê°œì˜ ì˜ìƒ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ.")
    except Exception as e:
        print(f"âŒ ì˜ìƒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    return videos


def get_comments(video_id):
    """
    ì˜ìƒ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëŒ“ê¸€ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    [ëŒ“ê¸€ ì‘ì„±ì¼, ëŒ“ê¸€ ë‚´ìš©] ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    comments = []
    try:
        request = youtube.commentThreads().list(
            part="snippet",
            videoId=video_id,
            maxResults=100,  # í˜ì´ì§€ë‹¹ ìµœëŒ€
            textFormat="plainText"
        )

        while request:
            response = request.execute()
            for item in response["items"]:
                snippet = item["snippet"]["topLevelComment"]["snippet"]
                # ìš”ì²­í•œ ì»¬ëŸ¼ 'date', 'comment'
                date = snippet["publishedAt"]
                text = snippet["textDisplay"]
                comments.append([date, text])

            # ë‹¤ìŒ í˜ì´ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
            if 'nextPageToken' in response:
                request = youtube.commentThreads().list_next(request, response)
            else:
                break  # ë‹¤ìŒ í˜ì´ì§€ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ

    except Exception as e:
        # ëŒ“ê¸€ì´ ë¹„í™œì„±í™”ëœ ê²½ìš°(403) ë“±ì€ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•˜ì§€ ì•Šê³  ë„˜ì–´ê°‘ë‹ˆë‹¤.
        pass

    return comments


def main():
    # 1. ì˜ìƒ ê²€ìƒ‰ (ID, ì œëª©, ì„¤ëª…)
    videos = search_videos(SEARCH_QUERY, MAX_VIDEOS)
    if not videos:
        print("ê²€ìƒ‰ëœ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    all_data = []  # ëª¨ë“  ëŒ“ê¸€ ë°ì´í„°ë¥¼ ëˆ„ì í•  ë¦¬ìŠ¤íŠ¸

    print("\nğŸ’¬ ê° ì˜ìƒì˜ ëŒ“ê¸€ ìˆ˜ì§‘ ì‹œì‘ (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)...")

    # 2. ê° ì˜ìƒì„ ìˆœíšŒí•˜ë©° ëŒ“ê¸€ ìˆ˜ì§‘
    for i, (video_id, title, content) in enumerate(videos):
        comments_list = get_comments(video_id)

        if not comments_list:  # ëŒ“ê¸€ ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
            print(f"   [{i + 1}/{len(videos)}] âš ï¸ ëŒ“ê¸€ ì—†ìŒ: {title[:30]}...")
            continue

        print(f"   [{i + 1}/{len(videos)}] âœ… ëŒ“ê¸€ {len(comments_list)}ê°œ ìˆ˜ì§‘: {title[:30]}...")

        # 3. ìˆ˜ì§‘ëœ ëŒ“ê¸€ì„ all_dataì— ì¶”ê°€
        for comment_date, comment_text in comments_list:
            # ìš”ì²­í•œ ì»¬ëŸ¼ ìˆœì„œ: title, content, comment, date
            all_data.append([
                title,
                content,
                comment_text,
                comment_date
            ])

        # API í• ë‹¹ëŸ‰ ì´ˆê³¼ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•œ ì•½ê°„ì˜ ëŒ€ê¸°
        time.sleep(0.1)

    # 4. ëª¨ë“  ë°ì´í„° ì·¨í•© ë° ì €ì¥
    if not all_data:
        print("\nëª¨ë“  ì˜ìƒì—ì„œ ìˆ˜ì§‘ëœ ëŒ“ê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"\nì´ {len(all_data)}ê°œì˜ ëŒ“ê¸€ì„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
    print("ë°ì´í„°í”„ë ˆì„ ìƒì„± ë° íŒŒì¼ ì €ì¥...")

    df = pd.DataFrame(all_data, columns=["title", "content", "comment", "date"])

    # íŒŒì¼ ì´ë¦„ ì„¤ì •
    safe_query = SEARCH_QUERY.replace(" ", "_")
    output_pickle = f"{safe_query}_aggregated_comments.pkl"
    output_excel = f"{safe_query}_aggregated_comments.xlsx"

    # í”¼í´ íŒŒì¼ë¡œ ì €ì¥
    try:
        df.to_pickle(output_pickle)
        print(f"ğŸ’¾ í”¼í´ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_pickle}")
    except Exception as e:
        print(f"âŒ í”¼í´ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")

    # ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥
    try:
        df.to_excel(output_excel, index=False, engine='openpyxl')
        print(f"ğŸ’¾ ì—‘ì…€ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_excel}")
    except Exception as e:
        print(f"âŒ ì—‘ì…€ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        print("   (ì°¸ê³ : 'openpyxl' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.)")

    print("\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")


if __name__ == "__main__":
    main()